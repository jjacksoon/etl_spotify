import os
from pathlib import Path
import pandas as pd 
import psycopg2
from psycopg2.extras import execute_batch
from dotenv import load_dotenv

#Carregando vari√°veis de ambiente
load_dotenv() # l√™ o arquivo .env e carrega as vari√°veis para o Python

BASE_DIR = Path(__file__).resolve().parents[3]
GOLD_DIR = BASE_DIR /"data"/"gold"  #dados da camada gold

DB_CONFIG = {
    "host": "localhost",
    "port": os.getenv("POSTGRES_PORT", 5432),
    "dbname": os.getenv("POSTGRES_DB"),
    "user": os.getenv("POSTGRES_USER"),
    "password": os.getenv("POSTGRES_PASSWORD"),
}

#Conex√£o
def get_connection():
    return psycopg2.connect(**DB_CONFIG)

#Carregando Dimens√£o artista em banco
def load_dim_artist():
    df = pd.read_csv(GOLD_DIR / "dim_artist.csv")

    #inserindo informa√ß√£o na tabela do banco - Se o artista j√° existir, ignora
    sql = """
        INSERT INTO gold.dim_artist (artist_id, artist_name)
        VALUES (%s,%s)
        ON CONFLICT (artist_id) DO NOTHING
    """

    with get_connection() as conn:      #conecta com o postgresql
        with conn.cursor() as cur:      #cria o cursor
            execute_batch(              #insere varias linhas de uma s√≥ vez
                cur,
                sql,
                df[["artist_id", "artist_name"]].values.tolist()
            )
        
        conn.commit()                   #confirma a trasacao no banco para que dados sejam gravados
    print(f"‚úÖ dim_artist carregada ({len(df)} registros)")



#Carregando dimens√£o album em banco
def load_dim_album():
    df = pd.read_csv(GOLD_DIR / "dim_album.csv")

    # üîß Corrige datas inv√°lidas
    df["album_release_date"] = pd.to_datetime(
        df["album_release_date"], errors="coerce"
    ).dt.date

    # üîß Converte NaN em None (NULL no Postgres)
    df = df.where(pd.notnull(df), None)

    sql = """
        INSERT INTO gold.dim_album (album_id, album_name, album_release_date, artist_id)
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (album_id) DO NOTHING;
    """

    with get_connection() as conn:
        with conn.cursor() as cur:
            execute_batch(
                cur,
                sql,
                df[["album_id", "album_name", "album_release_date", "artist_id"]]
                .values.tolist()
            )
        conn.commit()

    print(f"‚úÖ dim_album carregada ({len(df)} registros)")


# Carregando dimens√£o track em banco
def load_dim_track():
    df = pd.read_csv(GOLD_DIR/"dim_track.csv")

    #Inserindo informa√ß√µes na tabela do banco - se track j√° existir, ignora
    sql = """
        INSERT INTO gold.dim_track(track_id, track_name, explicit, popularity)
        VALUES(%s,%s,%s,%s)
        ON CONFLICT (track_id) DO NOTHING
    """
    with get_connection() as conn:
        with conn.cursor() as cur:
            execute_batch(
                cur,
                sql,
                df[["track_id", "track_name", "explicit", "popularity"]].values.tolist()
            )
        conn.commit()

    print(f"‚úÖ dim_track carregada ({len(df)} registros)")


#Carregando tabela fato em banco
def load_fact_recently_played():
    df = pd.read_csv(
        GOLD_DIR/"fact_recently_played.csv",
        parse_dates = ["played_at"]
        )

    #Inserindo informa√ß√µes na tabela do banco - se faixa ouvida j√° existir, ingnora
    sql = """
        INSERT INTO gold.fact_recently_played(played_at, track_id, album_id, duration_ms)
        VALUES(%s,%s,%s,%s)
        ON CONFLICT (played_at, track_id) DO NOTHING
    """

    with get_connection() as conn:
        with conn.cursor() as cur:
            execute_batch(
                cur,
                sql,
                df[["played_at", "track_id", "album_id", "duration_ms"]].values.tolist()
            )
        conn.commit()

    print(f"‚úÖ fact_recently_played carregada ({len(df)} registros)")


def run_load_gold_to_db():
    print("üóÑÔ∏è Iniciando carga da GOLD no PostgreSQL")

    load_dim_artist()
    load_dim_album()
    load_dim_track()
    load_fact_recently_played()

    print("‚úÖ Carga da GOLD no PostgreSQL finalizada")
